{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"http://camma.u-strasbg.fr/\">\n",
    "<img src=\"lib/camma_logo.png\" width=\"18%\">\n",
    "</a>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Weakly-supervised ConvLSTM Surgical Tool Tracker\n",
    "================\n",
    "------\n",
    "**A re-implementation of surgical tool tracker in**<br>\n",
    "<i>Nwoye, C. I., Mutter, D., Marescaux, J., & Padoy, N. (2019). \n",
    "    Weakly supervised convolutional LSTM approach for tool tracking in laparoscopic videos. \n",
    "    International journal of computer assisted radiology and surgery, 14(6), 1059-1067.<br></i>\n",
    "    <b> Please cite this paper, if you use this code or part of it.. </b>\n",
    "    \n",
    "    \n",
    "(c) Research Group CAMMA, University of Strasbourg, France<br>\n",
    "Website: http://camma.u-strasbg.fr<br>\n",
    "Code author: Chinedu Nwoye <br>\n",
    "    \n",
    "-----\n",
    "\n",
    "This provides the code for:\n",
    "    1. Model architecture and all its libraries\n",
    "    2. Evaluation\n",
    "    3. Visualization\n",
    "\n",
    "The code uses tf.contrib lib. TensorFlow version > 1.12 is discouraged."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "CODE RELEASE FOR MODEL EVALUATION AND COMPARISON ONLY.\n",
    "This code is released for scientific research only. \n",
    "Commercial or industrial use of any part must be with explicit written permission from CAMMA.\n",
    "#==============================================================================\n",
    "Weakly-supervised ConvLSTM Tracker --- an implementation based on:\n",
    "***\n",
    "    Nwoye, C. I., Mutter, D., Marescaux, J., & Padoy, N. (2019). \n",
    "    Weakly supervised convolutional LSTM approach for tool tracking in laparoscopic videos. \n",
    "    International journal of computer assisted radiology and surgery, 14(6), 1059-1067.\n",
    "***  \n",
    "Created on Mon Oct 21 09:30:47 2019\n",
    "#==============================================================================  \n",
    "Copyright 2019 The Research Group CAMMA Authors All Rights Reserved.\n",
    "(c) Research Group CAMMA, University of Strasbourg, France\n",
    "@ Laboratory: CAMMA - ICube\n",
    "@ Author: Nwoye Chinedu Innocent\n",
    "@ Website: http://camma.u-strasbg.fr\n",
    "#==============================================================================\n",
    " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " you may not use this file except in compliance with the License.\n",
    " You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    " Unless required by applicable law or agreed to in writing, software\n",
    " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " See the License for the specific language governing permissions and\n",
    " limitations under the License.\n",
    "#==============================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Download code and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/CAMMA-public/ConvLSTM-Surgical-Tool-Tracker.git\n",
    "%cd ConvLSTM-Surgical-Tool-Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Download sample video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --content-disposition https://s3.unistra.fr/camma_public/github/convlstm_tracker/data.zip\n",
    "!unzip data.zip\n",
    "print(\"Download completed ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Download model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --content-disposition https://s3.unistra.fr/camma_public/github/convlstm_tracker/ckpt.zip\n",
    "!unzip ckpt.zip\n",
    "print(\"Download completed ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some important installationns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow\n",
    "!pip install tensorflow-gpu==1.14\n",
    "!pip install imageio\n",
    "!pip install imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "import sys\n",
    "from matplotlib import animation, rc, pyplot as plt\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "from IPython.display import HTML\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline\n",
    "print(\"imports success...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables & Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height   = 480 #@param {type:\"integer\"}\n",
    "img_width    = 854 #@param {type:\"integer\"}\n",
    "img_channel  = 3   #@param {type:\"integer\"}\n",
    "num_classes  = 7   #@param {type:\"integer\"}\n",
    "offset_x     = 20  #@param {type:\"integer\"}\n",
    "offset_y     = 11  #@param {type:\"integer\"}\n",
    "gpu_usable   = 0   #@param {type:\"integer\"}\n",
    "data_path    = 'data/surgical_video.avi' #@param {type:\"string\"} you can modify this if you evaluate on a different video\n",
    "ckpt_path    = 'ckpt' #@param {type:\"string\"}\n",
    "            \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_usable) \n",
    "print(\"Variables set, model to run on Device: GPU: \", gpu_usable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ph  = tf.placeholder(dtype=tf.float32, shape=[None,None,3], name='inputs')\n",
    "x       = tf.expand_dims(img_ph, 0)   \n",
    "x       = tf.image.resize_bilinear(x, size=(480,854))             \n",
    "seek_ph = tf.placeholder(dtype=tf.int64, shape=[None], name='inputs')\n",
    "network = model.Model(images=x, seek=seek_ph, num_classes=num_classes)\n",
    "logits, lhmaps  = network.build_model() \n",
    "logits  = tf.cast(tf.round(tf.sigmoid(logits)), tf.int32)\n",
    "lhmaps  = lhmaps * tf.cast(logits, tf.float32)\n",
    "\n",
    "print(\"Model loaded successfully...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saver and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"saver_and_writer\"):                  \n",
    "    saver = tf.train.Saver()  \n",
    "    state = tf.train.get_checkpoint_state(ckpt_path)\n",
    "    ckpt  = state.model_checkpoint_path\n",
    "\n",
    "print('Loading checkpoint from :',ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate on video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS    = []\n",
    "CLASS_LHMAPS   = []\n",
    "reader         = imageio.get_reader(data_path)\n",
    "sess_config    = tf.ConfigProto(gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9), allow_soft_placement = True, log_device_placement = False) \n",
    "with tf.Session(config=sess_config) as sess:   \n",
    "    sess.run([tf.local_variables_initializer(), tf.global_variables_initializer()])\n",
    "    saver.restore(sess, ckpt)\n",
    "    for seek, frame in enumerate(reader):\n",
    "        predict, lhmap = sess.run([logits, lhmaps], feed_dict={img_ph:frame, seek_ph:[seek]})\n",
    "        PREDICTIONS.append(predict)\n",
    "        CLASS_LHMAPS.append(lhmap)\n",
    "        \n",
    "print(\"Evaluation done...\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates\n",
    "\n",
    "def get_center_coordinates(lhmap):\n",
    "    coord = np.where(lhmap == lhmap.max()) \n",
    "    cx    = (coord[1][0] * 854 // 107) + offset_x\n",
    "    cy    = (coord[0][0] * 480 // 60 ) + offset_y\n",
    "    return (cx, cy)\n",
    "\n",
    "def get_box_coordinates(lhmap):\n",
    "    coord = np.where(lhmap>0)\n",
    "    if len(coord[0])>0 and len(coord[1])>0 :\n",
    "        x0 = (coord[1].min() * 854 // 107) - offset_x\n",
    "        x1 = (coord[1].max() * 854 // 107) + offset_x\n",
    "        y0 = (coord[0].min() * 480 // 60) - offset_y\n",
    "        y1 = (coord[0].max() * 480 // 60) + offset_y\n",
    "    else:\n",
    "        x0,x1,y0,y1 = -1,-1,-1,-1\n",
    "    return (x0,y0,x1,y1)\n",
    "\n",
    "\n",
    "# Build animators\n",
    "def build_animators():\n",
    "    BUFFER_BOX_CENTER = []\n",
    "    colors    = [(255,0,0),(255,255,0),(0,0,255),(255,0,255),(255,128,0),(0,255,255),(0,255,0)] \n",
    "    radius    = 28\n",
    "    thickness = 4\n",
    "    reader    = imageio.get_reader(data_path)\n",
    "    fig       = plt.figure()\n",
    "    for k, (img, predict, lhmap) in enumerate(zip(reader, PREDICTIONS, CLASS_LHMAPS)):\n",
    "        img_overlay     = img.copy()\n",
    "        for i in range(num_classes):\n",
    "            cam         = lhmap[0,:,:,i]\n",
    "            x1,y1,x2,y2 = get_box_coordinates(cam)\n",
    "            cx,cy       = get_center_coordinates(cam)\n",
    "            color       = colors[i]\n",
    "            cv2.rectangle(img_overlay, (x1,y1), (x2,y2), color, thickness)\n",
    "            cv2.circle(img_overlay, (cx,cy), radius, color, -1)\n",
    "        cv2.circle(img_overlay, (offset_x,offset_y), radius, (0,0,0), -1)\n",
    "        BUFFER_BOX_CENTER.append([plt.imshow(img_overlay)])\n",
    "    return fig, BUFFER_BOX_CENTER\n",
    "        \n",
    "\n",
    "# Colorizer\n",
    "def cstr(s, color='black'):\n",
    "    return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "\n",
    "print(\"Model ready to track...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the video\n",
    "Let's track the instruments in the video<br>\n",
    "Colormap: display the legend for the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, OVERLAY = build_animators()\n",
    "\n",
    "HTML('='*20+\"> [  Tool Colormap:                                       \"\n",
    "           +cstr(\"Grasper\", \"red\") +\" | \"+cstr(\"Bipolar\", \"yellow\") +\"  |  \"+cstr(\"Hook\", \"blue\")+\"  |  \"\n",
    "           +cstr(\"Scissors\", \"violet\")+\"  |  \" +cstr(\"Clipper\", \"orange\") \n",
    "           +\"  |  \"+cstr(\"Irrigator\", \"mouve\") +\"  |  \"+cstr(\"Specimen bag  \", \"green\")+'  ] <'+'='*20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = animation.ArtistAnimation(fig, OVERLAY, interval=160, blit=True, repeat_delay=1000)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
